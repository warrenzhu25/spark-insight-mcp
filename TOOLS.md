# ğŸ› ï¸ Available MCP Tools

> **Note**: These tools are subject to change as we scale and improve the performance of the MCP server.

The MCP server provides **22 specialized tools** organized by analysis patterns. LLMs can intelligently select and combine these tools based on user queries:

## ğŸ“Š Application Information
*Basic application metadata and overview*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `get_application` | ğŸ“Š Get detailed information about a specific Spark application including status, resource usage, duration, and attempt details |
| `list_applications` | ğŸ“‹ Get a list of all Spark applications with optional filtering by status, dates, limits, and name patterns (exact, contains, regex) |

## ğŸ”— Job Analysis
*Job-level performance analysis and identification*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `list_jobs` | ğŸ”— Get a list of all jobs for a Spark application with optional status filtering |
| `list_slowest_jobs` | â±ï¸ Get the N slowest jobs for a Spark application (excludes running jobs by default) |

## âš¡ Stage Analysis
*Stage-level performance deep dive and task metrics*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `list_stages` | âš¡ Get a list of all stages for a Spark application with optional status filtering and summaries |
| `list_slowest_stages` | ğŸŒ Get the N slowest stages for a Spark application (excludes running stages by default) |
| `get_stage` | ğŸ¯ Get information about a specific stage with optional attempt ID and summary metrics |
| `get_stage_task_summary` | ğŸ“Š Get statistical distributions of task metrics for a specific stage (execution times, memory usage, I/O metrics) |

## ğŸ–¥ï¸ Executor & Resource Analysis
*Resource utilization, executor performance, and allocation tracking*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `list_executors` | ğŸ–¥ï¸ Get executor information with optional inactive executor inclusion |
| `get_executor` | ğŸ” Get information about a specific executor including resource allocation, task statistics, and performance metrics |
| `get_executor_summary` | ğŸ“ˆ Aggregates metrics across all executors (memory usage, disk usage, task counts, performance metrics) |
| `get_resource_usage_timeline` | ğŸ“… Get chronological view of resource allocation and usage patterns including executor additions/removals |

## âš™ï¸ Configuration & Environment
*Spark configuration, environment variables, and runtime settings*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `get_environment` | âš™ï¸ Get comprehensive Spark runtime configuration including JVM info, Spark properties, system properties, and classpath |

## ğŸ” SQL & Query Analysis
*SQL performance analysis and execution plan comparison*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `list_slowest_sql_queries` | ğŸŒ Get the top N slowest SQL queries for an application with detailed execution metrics |
| `compare_sql_execution_plans` | ğŸ” Compare SQL execution plans between two Spark jobs, analyzing logical/physical plans and execution metrics |

## ğŸš¨ Performance & Bottleneck Analysis
*Intelligent bottleneck identification and performance recommendations*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `get_job_bottlenecks` | ğŸš¨ Identify performance bottlenecks by analyzing stages, tasks, and executors with actionable recommendations |

## ğŸ”„ Comparative Analysis
*Cross-application comparison for regression detection and optimization*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `compare_job_environments` | âš™ï¸ Compare Spark environment configurations between two jobs to identify differences in properties and settings |
| `compare_job_performance` | ğŸ“ˆ Compare performance metrics between two Spark jobs including execution times, resource usage, and task distribution |

## ğŸ§  SparkInsight Intelligence
*AI-powered analysis tools inspired by SparkInsight for intelligent performance optimization*
| ğŸ”§ Tool | ğŸ“ Description |
|---------|----------------|
| `analyze_auto_scaling` | ğŸš€ Analyze workload patterns and provide intelligent auto-scaling recommendations for dynamic allocation |
| `analyze_shuffle_skew` | ğŸ“Š Detect and analyze data skew in shuffle operations with actionable optimization suggestions |
| `analyze_failed_tasks` | ğŸš¨ Investigate task failures to identify patterns, problematic executors, and root causes |
| `analyze_executor_utilization` | ğŸ“ˆ Track executor utilization over time to identify over/under-provisioning and optimization opportunities |
| `get_application_insights` | ğŸ§  **Comprehensive SparkInsight analysis** - Runs all analyzers to provide complete performance overview and recommendations |

## ğŸ¤– How LLMs Use These Tools

**Query Pattern Examples:**
- *"Why is my job slow?"* â†’ `get_job_bottlenecks` + `list_slowest_stages` + `get_executor_summary`
- *"Compare today vs yesterday"* â†’ `compare_job_performance` + `compare_job_environments`
- *"What's wrong with stage 5?"* â†’ `get_stage` + `get_stage_task_summary`
- *"Show me resource usage over time"* â†’ `get_resource_usage_timeline` + `get_executor_summary`
- *"Find my slowest SQL queries"* â†’ `list_slowest_sql_queries` + `compare_sql_execution_plans`
- *"Analyze my app performance with insights"* â†’ `get_application_insights` (comprehensive SparkInsight analysis)
- *"Help me optimize auto-scaling"* â†’ `analyze_auto_scaling` + `analyze_executor_utilization`
- *"Why are my tasks failing?"* â†’ `analyze_failed_tasks` + `get_executor_summary`
- *"Check for data skew issues"* â†’ `analyze_shuffle_skew` + `get_stage_task_summary`